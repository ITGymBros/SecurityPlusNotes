
Input Validation is to ensure date inputs are valid. Syntactic validation (for example putting in the correct amount of numbers when entering a credit card or social security number) and semantic validation (for example the start date of a new employee) are forms of input validation. Schemas are used to formulate and regulate how information is supposed to be written and what is considered valid data formatting or not.

Blacklisting is when you are banning certain things, not allowing certain characters to be used (one reason for this restriction is to prevent a SQL injection attack). Blacklisting characters can be hard to maintain due to potentially missing some obscure characters from another language. Whitelisting is the opposite of blacklisting, this is where you have a list of acceptable characters that can be used. This downside to whitelisting is you could potentially break something (like an application) if there is a character required, but isn't on that whitelist.

HTTP Headers can be used to upload files if they're not secured properly. They can be used to leak information like internal hostnames, backend server information, and what type of applications are being ran.

Code Signing uses certificates from the software author. This is to ensure the codes integrity via digital signatures (this is great to ensure not only that you were the one wanting to install said software, but also to verify that the software being installed is from a valid source).

**Secure Cookies** are specifically created to **NOT** include/store sensitive information. It's even more important to use HTTPS vs. HTTP, this will ensure encryption so you won't have hackers attempting eavesdropping attacks or man in the middle attacks to try and gain your cookies. Secure cookie flags validates the integrity of the cookie. Secure cookie flags can be bypassed or altered if a hacker was able to grab that cookie, modify it, and get it back to you (that validator could also hold sensitive information for the hacker to gain).

**Static Code Analysis** is an automated scan, but the code/software is not actively running. This is really good for things like source code. The open source code movement allows us to download and inspect any open source code/software and check ourselves for any potential threats/vulnerabilities (early detection of issues in the software development life cycle).

**Dynamic Code Analysis** is also an automated scan, the difference is this code/software is actively running. This is to try to figure out how the code is interacting/behaving. For example, if an application is working with/communicating with other applications like a backend database server, analyzing how it's interacting with that server is important.

**Manual Code Analysis** introduces the human element. This is a slow process due to humans being the ones to check the code line by line, this is not an automated process. Since this type of analysis has human element involved, this form of code analysis is open to interpretation.

**Fuzzing** is an automated process where you throw random, valid, invalid, and unexpected data into the mix to see how the software responds to these different types of data. For example, if you typed an invalid piece of data into a field, what type of error message is displayed (types a valid username, but an invalid password. If the error message indicates you only typed an invalid password, this provides unnecessary information that can be used to try to break into a system). Also inputting all these random types of information can be used to see if there are **memory leaks** that can be caused, crashes of the software/code, and or a **buffer overflow**.